{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZtskxrQyg3e"
      },
      "source": [
        "# TASK 1 : Install Dependencies & Run a SparkSession\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a9huiQF8yfIK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in c:\\python310\\lib\\site-packages (3.3.0)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in c:\\python310\\lib\\site-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ],
      "source": [
        "#install pyspark\n",
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1wZpO2gxy7Pt"
      },
      "outputs": [],
      "source": [
        "#create a sparksession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"graduate\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t7JFc_My__A"
      },
      "source": [
        "# TASK 2 : Clone & Explore dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C0oRpI4ezFgc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'admission_dataset' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "#clone the dataset\n",
        "! git clone https://github.com/education454/admission_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q6sF2NVazjtU"
      },
      "outputs": [],
      "source": [
        "#create a spark dataframe\n",
        "file = 'Admission_Predict_Ver1.1.csv'\n",
        "df = spark.read.csv(file, header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cG6UhIUuznfJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
            "|Serial No|GRE Score|TOEFL Score|University Rating|SOP|LOR|CGPA|Research|Chance of Admit|\n",
            "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
            "|        1|      337|        118|                4|4.5|4.5|9.65|       1|           0.92|\n",
            "|        2|      324|        107|                4|4.0|4.5|8.87|       1|           0.76|\n",
            "|        3|      316|        104|                3|3.0|3.5| 8.0|       1|           0.72|\n",
            "|        4|      322|        110|                3|3.5|2.5|8.67|       1|            0.8|\n",
            "|        5|      314|        103|                2|2.0|3.0|8.21|       0|           0.65|\n",
            "|        6|      330|        115|                5|4.5|3.0|9.34|       1|            0.9|\n",
            "|        7|      321|        109|                3|3.0|4.0| 8.2|       1|           0.75|\n",
            "|        8|      308|        101|                2|3.0|4.0| 7.9|       0|           0.68|\n",
            "|        9|      302|        102|                1|2.0|1.5| 8.0|       0|            0.5|\n",
            "|       10|      323|        108|                3|3.5|3.0| 8.6|       0|           0.45|\n",
            "|       11|      325|        106|                3|3.5|4.0| 8.4|       1|           0.52|\n",
            "|       12|      327|        111|                4|4.0|4.5| 9.0|       1|           0.84|\n",
            "|       13|      328|        112|                4|4.0|4.5| 9.1|       1|           0.78|\n",
            "|       14|      307|        109|                3|4.0|3.0| 8.0|       1|           0.62|\n",
            "|       15|      311|        104|                3|3.5|2.0| 8.2|       1|           0.61|\n",
            "|       16|      314|        105|                3|3.5|2.5| 8.3|       0|           0.54|\n",
            "|       17|      317|        107|                3|4.0|3.0| 8.7|       0|           0.66|\n",
            "|       18|      319|        106|                3|4.0|3.0| 8.0|       1|           0.65|\n",
            "|       19|      318|        110|                3|4.0|3.0| 8.8|       0|           0.63|\n",
            "|       20|      303|        102|                3|3.5|3.0| 8.5|       0|           0.62|\n",
            "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#display dataframe\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tgtWocArzqVR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500, 9)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get the no.of rows & columns\n",
        "df.count(), len(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OWQTe006zt7O"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Serial No: integer (nullable = true)\n",
            " |-- GRE Score: integer (nullable = true)\n",
            " |-- TOEFL Score: integer (nullable = true)\n",
            " |-- University Rating: integer (nullable = true)\n",
            " |-- SOP: double (nullable = true)\n",
            " |-- LOR: double (nullable = true)\n",
            " |-- CGPA: double (nullable = true)\n",
            " |-- Research: integer (nullable = true)\n",
            " |-- Chance of Admit: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#print schema \n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "locEx8HDz264"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
            "|summary|        Serial No|         GRE Score|      TOEFL Score|University Rating|               SOP|               LOR|              CGPA|          Research|    Chance of Admit|\n",
            "+-------+-----------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
            "|  count|              500|               500|              500|              500|               500|               500|               500|               500|                500|\n",
            "|   mean|            250.5|           316.472|          107.192|            3.114|             3.374|             3.484| 8.576440000000003|              0.56| 0.7217399999999996|\n",
            "| stddev|144.4818327679989|11.295148372354712|6.081867659564538|1.143511800759815|0.9910036207566072|0.9254495738978191|0.6048128003332054|0.4968840786090358|0.14114040395030228|\n",
            "|    min|                1|               290|               92|                1|               1.0|               1.0|               6.8|                 0|               0.34|\n",
            "|    max|              500|               340|              120|                5|               5.0|               5.0|              9.92|                 1|               0.97|\n",
            "+-------+-----------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#get the summary statistics\n",
        "df.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uDdoEKsz6h6"
      },
      "source": [
        "# TASK 3 : Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "o6gJAFo30G9s"
      },
      "outputs": [],
      "source": [
        "#drop the unnecessary column\n",
        "df = df.drop('Serial No.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_lOPoDVk0OFH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
            "|Serial No|GRE Score|TOEFL Score|University Rating|SOP|LOR|CGPA|Research|Chance of Admit|\n",
            "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
            "|        1|      337|        118|                4|4.5|4.5|9.65|       1|           0.92|\n",
            "|        2|      324|        107|                4|4.0|4.5|8.87|       1|           0.76|\n",
            "|        3|      316|        104|                3|3.0|3.5| 8.0|       1|           0.72|\n",
            "|        4|      322|        110|                3|3.5|2.5|8.67|       1|            0.8|\n",
            "|        5|      314|        103|                2|2.0|3.0|8.21|       0|           0.65|\n",
            "|        6|      330|        115|                5|4.5|3.0|9.34|       1|            0.9|\n",
            "|        7|      321|        109|                3|3.0|4.0| 8.2|       1|           0.75|\n",
            "|        8|      308|        101|                2|3.0|4.0| 7.9|       0|           0.68|\n",
            "|        9|      302|        102|                1|2.0|1.5| 8.0|       0|            0.5|\n",
            "|       10|      323|        108|                3|3.5|3.0| 8.6|       0|           0.45|\n",
            "|       11|      325|        106|                3|3.5|4.0| 8.4|       1|           0.52|\n",
            "|       12|      327|        111|                4|4.0|4.5| 9.0|       1|           0.84|\n",
            "|       13|      328|        112|                4|4.0|4.5| 9.1|       1|           0.78|\n",
            "|       14|      307|        109|                3|4.0|3.0| 8.0|       1|           0.62|\n",
            "|       15|      311|        104|                3|3.5|2.0| 8.2|       1|           0.61|\n",
            "|       16|      314|        105|                3|3.5|2.5| 8.3|       0|           0.54|\n",
            "|       17|      317|        107|                3|4.0|3.0| 8.7|       0|           0.66|\n",
            "|       18|      319|        106|                3|4.0|3.0| 8.0|       1|           0.65|\n",
            "|       19|      318|        110|                3|4.0|3.0| 8.8|       0|           0.63|\n",
            "|       20|      303|        102|                3|3.5|3.0| 8.5|       0|           0.62|\n",
            "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#display the dataframe\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Au73oUZJ0Qv7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Serial No: 0\n",
            "GRE Score: 0\n",
            "TOEFL Score: 0\n",
            "University Rating: 0\n",
            "SOP: 0\n",
            "LOR: 0\n",
            "CGPA: 0\n",
            "Research: 0\n",
            "Chance of Admit: 0\n"
          ]
        }
      ],
      "source": [
        "#check for null values\n",
        "for i in df.columns:\n",
        "    print(i+\":\" ,df[df[i].isNull()].count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prkDI9Dc0SoH"
      },
      "source": [
        "# TASK 4 : Correlation Analysis & Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eFhxSRRj0Ypa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation of chance to admit col for Serial No is 0.00850504936113174\n",
            "Correlation of chance to admit col for GRE Score is 0.8103506354632598\n",
            "Correlation of chance to admit col for TOEFL Score is 0.7922276143050823\n",
            "Correlation of chance to admit col for University Rating is 0.6901323687886892\n",
            "Correlation of chance to admit col for SOP is 0.6841365241316723\n",
            "Correlation of chance to admit col for LOR is 0.6453645135280112\n",
            "Correlation of chance to admit col for CGPA is 0.882412574904574\n",
            "Correlation of chance to admit col for Research is 0.5458710294711379\n",
            "Correlation of chance to admit col for Chance of Admit is 1.0\n"
          ]
        }
      ],
      "source": [
        "# correlation analysis\n",
        "for col in df.columns:\n",
        "    print('Correlation of chance to admit col for {} is {}'.format(col,df.stat.corr('Chance of Admit', col)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UXNOknvo0dV2"
      },
      "outputs": [],
      "source": [
        "# feature selection\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=['GRE Score', 'TOEFL Score', 'CGPA'], outputCol='features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JOzlkPaz0ibL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+------------------+\n",
            "|Serial No|GRE Score|TOEFL Score|University Rating|SOP|LOR|CGPA|Research|Chance of Admit|          features|\n",
            "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+------------------+\n",
            "|        1|      337|        118|                4|4.5|4.5|9.65|       1|           0.92|[337.0,118.0,9.65]|\n",
            "|        2|      324|        107|                4|4.0|4.5|8.87|       1|           0.76|[324.0,107.0,8.87]|\n",
            "|        3|      316|        104|                3|3.0|3.5| 8.0|       1|           0.72| [316.0,104.0,8.0]|\n",
            "|        4|      322|        110|                3|3.5|2.5|8.67|       1|            0.8|[322.0,110.0,8.67]|\n",
            "|        5|      314|        103|                2|2.0|3.0|8.21|       0|           0.65|[314.0,103.0,8.21]|\n",
            "|        6|      330|        115|                5|4.5|3.0|9.34|       1|            0.9|[330.0,115.0,9.34]|\n",
            "|        7|      321|        109|                3|3.0|4.0| 8.2|       1|           0.75| [321.0,109.0,8.2]|\n",
            "|        8|      308|        101|                2|3.0|4.0| 7.9|       0|           0.68| [308.0,101.0,7.9]|\n",
            "|        9|      302|        102|                1|2.0|1.5| 8.0|       0|            0.5| [302.0,102.0,8.0]|\n",
            "|       10|      323|        108|                3|3.5|3.0| 8.6|       0|           0.45| [323.0,108.0,8.6]|\n",
            "|       11|      325|        106|                3|3.5|4.0| 8.4|       1|           0.52| [325.0,106.0,8.4]|\n",
            "|       12|      327|        111|                4|4.0|4.5| 9.0|       1|           0.84| [327.0,111.0,9.0]|\n",
            "|       13|      328|        112|                4|4.0|4.5| 9.1|       1|           0.78| [328.0,112.0,9.1]|\n",
            "|       14|      307|        109|                3|4.0|3.0| 8.0|       1|           0.62| [307.0,109.0,8.0]|\n",
            "|       15|      311|        104|                3|3.5|2.0| 8.2|       1|           0.61| [311.0,104.0,8.2]|\n",
            "|       16|      314|        105|                3|3.5|2.5| 8.3|       0|           0.54| [314.0,105.0,8.3]|\n",
            "|       17|      317|        107|                3|4.0|3.0| 8.7|       0|           0.66| [317.0,107.0,8.7]|\n",
            "|       18|      319|        106|                3|4.0|3.0| 8.0|       1|           0.65| [319.0,106.0,8.0]|\n",
            "|       19|      318|        110|                3|4.0|3.0| 8.8|       0|           0.63| [318.0,110.0,8.8]|\n",
            "|       20|      303|        102|                3|3.5|3.0| 8.5|       0|           0.62| [303.0,102.0,8.5]|\n",
            "+---------+---------+-----------+-----------------+---+---+----+--------+---------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#display dataframe\n",
        "output_data=assembler.transform(df)\n",
        "output_data.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6FucLAC0r5I"
      },
      "source": [
        "# TASK 5 : Build the Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RMYN_8jJ0wDR"
      },
      "outputs": [],
      "source": [
        "#import Linearregression and create final data\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "final_df = output_data.select('features','Chance of Admit')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MNSEfLCp09oO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- features: vector (nullable = true)\n",
            " |-- Chance of Admit: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#print schema of final data\n",
        "final_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vOJylIiS1Dre"
      },
      "outputs": [],
      "source": [
        "#split the dataset into training and testing set\n",
        "train, test = final_df.randomSplit([0.7,0.3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xoxFzm4A1Hee"
      },
      "outputs": [],
      "source": [
        "#build & train the model\n",
        "models = LinearRegression(featuresCol='features', labelCol='Chance of Admit')\n",
        "model = models.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DDCZ9uvA1QLf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficients: [0.0020456484394370082,0.003559155058733461,0.1476993697184929]\n",
            "Intercept: -1.571734159696103\n"
          ]
        }
      ],
      "source": [
        "#get coefficients & intercept\n",
        "print(\"Coefficients:\",model.coefficients)\n",
        "print(\"Intercept:\",model.intercept)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bO6Duj1l1YJX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyspark.ml.regression.LinearRegressionTrainingSummary at 0x20f93fd7070>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get summary of the model\n",
        "summary = model.summary\n",
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ebi9LxFS1aBJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE 0.05913735430017819\n",
            "r2 score: 0.8229184987147455\n"
          ]
        }
      ],
      "source": [
        "#print the rmse & r2 score\n",
        "print(\"RMSE\", summary.rootMeanSquaredError)\n",
        "print(\"r2 score:\",summary.r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5lTskfK1eKV"
      },
      "source": [
        "# TASK 6 : Evaluate & Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "l0TAwvGP1noC"
      },
      "outputs": [],
      "source": [
        "#transform on the test data\n",
        "predictions = model.transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "T_DixZ6f1nvP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+---------------+-------------------+\n",
            "|          features|Chance of Admit|         prediction|\n",
            "+------------------+---------------+-------------------+\n",
            "|[290.0,104.0,7.46]|           0.45| 0.4934933119488665|\n",
            "|  [293.0,97.0,7.8]|           0.64| 0.5249339575603307|\n",
            "| [295.0,96.0,7.34]|           0.47|0.45752438930996475|\n",
            "| [296.0,99.0,8.03]|           0.61| 0.5721600680313619|\n",
            "|[296.0,101.0,7.68]|            0.6| 0.5275835987473567|\n",
            "| [297.0,96.0,7.43]|           0.34|  0.474908629463503|\n",
            "| [297.0,99.0,7.81]|           0.54| 0.5417118551327305|\n",
            "|[297.0,101.0,7.67]|           0.57| 0.5281522534896086|\n",
            "| [298.0,92.0,7.88]|           0.51|  0.529182374041328|\n",
            "| [298.0,97.0,7.21]|           0.45|0.44801957162360506|\n",
            "| [298.0,98.0,8.03]|           0.34| 0.5726922098515026|\n",
            "|[298.0,100.0,7.95]|           0.58| 0.5679945703914904|\n",
            "| [299.0,97.0,7.66]|           0.38|  0.516529936436364|\n",
            "|[299.0,100.0,7.89]|           0.59| 0.5611782566478174|\n",
            "| [301.0,96.0,7.56]|           0.54|  0.502292141284655|\n",
            "| [301.0,98.0,8.03]|           0.67| 0.5788291551698135|\n",
            "|[301.0,104.0,7.89]|           0.68| 0.5795061737616252|\n",
            "| [302.0,99.0,7.25]|           0.57|0.46922845028755966|\n",
            "|[302.0,101.0,7.96]|           0.46| 0.5812133129051567|\n",
            "| [302.0,102.0,8.0]|            0.5| 0.5906804427526298|\n",
            "+------------------+---------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#display the predictions\n",
        "predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vzxDnudZ1n3n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "r2 on the test data 0.7550065757897368\n"
          ]
        }
      ],
      "source": [
        "#evaluate the model\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='Chance of Admit', metricName='r2')\n",
        "print(\"r2 on the test data\",evaluator.evaluate(predictions)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEeyiruX1n_I"
      },
      "outputs": [],
      "source": [
        "#save the model\n",
        "model.save(\"model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK48FYRd2CMJ"
      },
      "outputs": [],
      "source": [
        "#load the model\n",
        "from pyspark.ml.regression import LinearRegressionModel\n",
        "model = LinearRegressionModel.load('model')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Admission_prediction_with_pyspark_ml.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
